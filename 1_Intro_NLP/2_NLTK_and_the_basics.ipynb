{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13256e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dont do this \n",
    "# !pip3 install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162fb4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1bf055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Project Gutenberg \n",
    "nltk.download('gutenberg') # To download the corpuse of Project Gutenberg\n",
    "nltk.download('punkt') # This package is required for Tokenisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329bd2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027e430b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the words from the book as a LIST\n",
    "md = nltk.corpus.gutenberg.words(\"melville-moby_dick.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8964e694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the first X elements of the list (first X words)\n",
    "md[:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ec587a",
   "metadata": {},
   "source": [
    "## Counting frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cccb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "md.count(\"whale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d3f3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "md.count(\"Whale\") # Case-sensitive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84ecb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "md.count(\"boat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf77e7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "md.count(\"Boat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e9bda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "md.count(\"laptop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa3f13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of the book\n",
    "len(md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad80350c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many UNIQUE words there are in the book\n",
    "\n",
    "# 1 Create a SET from md\n",
    "md_set = set(md)\n",
    "\n",
    "# 2 Get the size (length) of the set \n",
    "print(\"Unique words in Moby Dick: \" + str(len(md_set)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c857cd",
   "metadata": {},
   "source": [
    "# Average nb of times a word is being used in the book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524e59e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(md)/len(md_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4431cfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# each word was used on average around 13 times along the book"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d61aab3",
   "metadata": {},
   "source": [
    "## Treat the book as sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6386da",
   "metadata": {},
   "outputs": [],
   "source": [
    "md_sents = nltk.corpus.gutenberg.sents(\"melville-moby_dick.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4940a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(md)/len(md_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfe7b2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0090a8e8",
   "metadata": {},
   "source": [
    "# FREQUENCY DISTIRBUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e293c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "alice = nltk.corpus.gutenberg.words(\"carroll-alice.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5e918c",
   "metadata": {},
   "outputs": [],
   "source": [
    "alice_fd = nltk.FreqDist(alice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b67145",
   "metadata": {},
   "outputs": [],
   "source": [
    "alice_fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402932d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "alice_fd[\"Rabbit\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597f7c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "alice_fd[\"rabbit\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fe6710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non descriptive words\n",
    "alice_fd.most_common(15) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53670b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "alice_fd.hapaxes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7051f8f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36712a4e",
   "metadata": {},
   "source": [
    "# CONDITIONAL FREQUENCY DISTRIBUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88718f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [('Group A','Paul'), ('Group A','Mike'),('Group A','Katy'),('Group B','Amy'),('Group B','Joe'),('Group B','Amy')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767261af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# it counts the touples as a whole\n",
    "nltk.FreqDist(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086ecdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It counts the names in each group\n",
    "nltk.ConditionalFreqDist(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d3bebf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4fa552ae",
   "metadata": {},
   "source": [
    "# INFORMATIVE WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9df48d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100 most common words for Alice in wonderland\n",
    "alice = nltk.corpus.gutenberg.words(\"carroll-alice.txt\")\n",
    "alice_fd = nltk.FreqDist(alice)\n",
    "alice_fd_100 = alice_fd.most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ac6220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100 most common words for Moby Dick\n",
    "moby = nltk.corpus.gutenberg.words(\"melville-moby_dick.txt\")\n",
    "moby_fd = nltk.FreqDist(moby)\n",
    "moby_fd_100 = moby_fd.most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edb9278",
   "metadata": {},
   "outputs": [],
   "source": [
    "alice_fd_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8585b7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "alice_100 = [word[0] for word in alice_fd_100]\n",
    "moby_100 = [word[0] for word in moby_fd_100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7806865b",
   "metadata": {},
   "outputs": [],
   "source": [
    "alice_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0026a89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subtracting the two sets of words. Words IN Alice but ABSENT in Moby\n",
    "set(alice_100) - set(moby_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7adeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(moby_100) - set(alice_100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b656d7f2",
   "metadata": {},
   "source": [
    "# BIGRAMS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce20a52b",
   "metadata": {},
   "source": [
    "Combinations or sequence of words that appear together in a text. One words -> gram, and we construct sequences of 2 words (bigrams) up to n words (n-grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559fb9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"I think it might rain today.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fb1b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nltk.word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ddc76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d26f50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the bigrams\n",
    "bigrams = nltk.bigrams(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa1d4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in bigrams:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd674f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trigrams\n",
    "trigrams = nltk.trigrams(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25446b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in trigrams:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbd8ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f7def1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = \"If it is nice out, I will go to the beach.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c483a8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nltk.word_tokenize(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96aef3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams_2 = ngrams(tokens,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d1774a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in bigrams_2:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb744afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fourgrams = ngrams(tokens,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b0a739",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in fourgrams:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3864340f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function if we're using this very frequently\n",
    "def n_grams(text,n):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    grams = ngrams(tokens,n)\n",
    "    return grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e70440",
   "metadata": {},
   "outputs": [],
   "source": [
    "text3 = text + \" \" + text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88712211",
   "metadata": {},
   "outputs": [],
   "source": [
    "text3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fce362",
   "metadata": {},
   "outputs": [],
   "source": [
    "grams = n_grams(text3,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70bcfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in grams:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4e71dc",
   "metadata": {},
   "source": [
    "# REGULAR EXPRESSION"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4ec51079",
   "metadata": {},
   "source": [
    "^      Start of string \n",
    "$      End of string \n",
    ".      Wild car character (any character)\n",
    "[chr]  Matches one of the characters inside the brackets\n",
    "[a-m]  Matches one character in the range\n",
    "?      The previous character occurs 0 or 1 times\n",
    "*      The previous character occurs 0 or more times\n",
    "+      The previous character occurs 1 or more times\n",
    "a|e    Matches one or the other character\n",
    "()     Parenthesis for grouping expressions\n",
    "\\      Escape character\n",
    "\n",
    "EXAMPLES:\n",
    "^...$         Matches all three-letter/character words\n",
    "^c..$         Matches all three-letter words starting with \"c\"\n",
    "^c            Matches all words starting by \"c\" regardless its length\n",
    "ing$          All words of any length that end in \"ing\"\n",
    "^[chr]at$     Matches the words cat/hat/rat in a document/text\n",
    "^[a-f]        All words starting with a/b/c/d/e/f\n",
    "^.+@.+\\.com$  Matches all the \".com\" email addresses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f568b63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "alice = nltk.corpus.gutenberg.words(\"carroll-alice.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4f7e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Words starting by 'new'\n",
    "set( [word for word in alice if re.search('^new',word) ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd8443c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Words ending in \"ful\"\n",
    "set([word for word in alice if re.search(\"ful$\",word)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ddc8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Words that are 6-character long and have two \"n\" in the middle\n",
    "set([word for word in alice if re.search(\"^..nn..$\",word)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9d6b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the words cat/hat/rat in the book\n",
    "set([word for word in alice if re.search(\"^[chr]at$\",word)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbf74c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all the words regardless their length, containning two 'n'\n",
    "set([word for word in alice if re.search(\"^.*nn.*$\",word)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e634b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All words starting with a vowel, where the 2nd letter is a \"c\" and the word ends in \"y\"\n",
    "set([word for word in alice if re.search(\"^[aeiou]c.+y$\",word)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754e1318",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
